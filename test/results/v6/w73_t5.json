[
    {
        "paper": "https://arxiv.org/abs/2503.23315",
        "summary": "This paper introduces AI “Design Agents” that automate and speed up car design, blending creativity, aerodynamics, and efficiency for faster, smarter automotive development.",
        "matched_users": [
            "U0332SAEU6P"
        ],
        "similarities": {
            "U0332SAEU6P": 0.4311,
            "U05BC4D4STU": 0.422,
            "U06AJGGHZ5L": 0.3927,
            "UAP5VEP2R": 0.3895,
            "U083D8Y0YJE": 0.3892,
            "U1LB1DXJS": 0.3786,
            "UUQ287SEQ": 0.3742,
            "U079D5P6P3M": 0.3603,
            "U03492H28Q3": 0.3447,
            "U08EN6WDKCP": 0.3272,
            "U06FXPDH4TF": 0.3153,
            "U08DG6LRQ3V": 0.3131,
            "U01HB3S0UM8": 0.3048,
            "U086M1L2F27": 0.3039,
            "U090X2QH2QK": 0.2927,
            "U07B3LG8M5E": 0.2795,
            "U025KUM8NSY": 0.2569,
            "U078YHXKTU7": 0.2462,
            "U086M1LK65R": 0.2435,
            "U090X2UUAN7": 0.2198,
            "U8JLRRXPB": 0.2179,
            "U07ABUCJWDT": 0.2152,
            "U03KJ9NJ1FU": 0.211,
            "U090X2ST9NF": 0.2023,
            "U090X2ZDC91": 0.1631,
            "U07PC9NTTNK": 0.1597,
            "U4D956LSC": 0.1484,
            "U090X2M5P8B": 0.1351,
            "U3M5HJ7MX": 0.0932
        }
    },
    {
        "paper": "https://arxiv.org/abs/2506.23678",
        "summary": "The paper introduces Interactive Reasoning, a system that visualizes and lets users edit AI’s thought chains, improving control, understanding, and personalization in large language models’ decision processes.",
        "matched_users": [
            "U06FXPDH4TF"
        ],
        "similarities": {
            "U06FXPDH4TF": 0.503,
            "U8JLRRXPB": 0.4916,
            "U079D5P6P3M": 0.4621,
            "U08DG6LRQ3V": 0.4606,
            "U03492H28Q3": 0.4324,
            "U086M1L2F27": 0.4218,
            "U1LB1DXJS": 0.419,
            "UAP5VEP2R": 0.4116,
            "U078YHXKTU7": 0.3992,
            "U025KUM8NSY": 0.3948,
            "UUQ287SEQ": 0.3557,
            "U083D8Y0YJE": 0.3472,
            "U03KJ9NJ1FU": 0.3469,
            "U0332SAEU6P": 0.3395,
            "U05BC4D4STU": 0.3354,
            "U06AJGGHZ5L": 0.3307,
            "U086M1LK65R": 0.3299,
            "U07ABUCJWDT": 0.3267,
            "U090X2QH2QK": 0.302,
            "U4D956LSC": 0.2842,
            "U01HB3S0UM8": 0.2817,
            "U08EN6WDKCP": 0.2813,
            "U07PC9NTTNK": 0.2673,
            "U090X2M5P8B": 0.2634,
            "U090X2UUAN7": 0.2508,
            "U07B3LG8M5E": 0.2177,
            "U090X2ZDC91": 0.2017,
            "U3M5HJ7MX": 0.1981,
            "U090X2ST9NF": 0.1953
        }
    },
    {
        "paper": "https://arxiv.org/abs/2409.08937",
        "summary": "The study finds hallucinations in AI reduce data quality, and Cognitive Forcing Functions have mixed effects, with users often overrelying on AI, even when responses are incorrect, impacting human-AI collaboration.",
        "matched_users": [
            "U08DG6LRQ3V"
        ],
        "similarities": {
            "U08DG6LRQ3V": 0.4677,
            "U03KJ9NJ1FU": 0.4382,
            "UAP5VEP2R": 0.4304,
            "U079D5P6P3M": 0.4229,
            "U03492H28Q3": 0.4195,
            "U083D8Y0YJE": 0.4176,
            "U1LB1DXJS": 0.4158,
            "UUQ287SEQ": 0.4142,
            "U06FXPDH4TF": 0.3883,
            "U086M1LK65R": 0.3531,
            "U086M1L2F27": 0.351,
            "U025KUM8NSY": 0.3471,
            "U06AJGGHZ5L": 0.3151,
            "U07PC9NTTNK": 0.3141,
            "U07ABUCJWDT": 0.3106,
            "U078YHXKTU7": 0.2944,
            "U05BC4D4STU": 0.2895,
            "U0332SAEU6P": 0.2872,
            "U8JLRRXPB": 0.286,
            "U08EN6WDKCP": 0.2628,
            "U01HB3S0UM8": 0.2603,
            "U090X2QH2QK": 0.2422,
            "U4D956LSC": 0.2365,
            "U07B3LG8M5E": 0.2225,
            "U090X2M5P8B": 0.2166,
            "U090X2ST9NF": 0.2033,
            "U090X2ZDC91": 0.2006,
            "U090X2UUAN7": 0.186,
            "U3M5HJ7MX": 0.1619
        }
    },
    {
        "paper": "https://arxiv.org/abs/2507.01921",
        "summary": "The paper introduces NaturalThoughts, a dataset of reasoning traces for improving general reasoning in language models. Selecting diverse, challenging examples boosts reasoning abilities efficiently.",
        "matched_users": [
            "U8JLRRXPB"
        ],
        "similarities": {
            "U8JLRRXPB": 0.5103,
            "U06FXPDH4TF": 0.4041,
            "U079D5P6P3M": 0.372,
            "U025KUM8NSY": 0.3353,
            "U08DG6LRQ3V": 0.3202,
            "U03KJ9NJ1FU": 0.2617,
            "UUQ287SEQ": 0.2607,
            "U07ABUCJWDT": 0.2575,
            "U0332SAEU6P": 0.242,
            "U1LB1DXJS": 0.2414,
            "U06AJGGHZ5L": 0.2397,
            "U03492H28Q3": 0.2379,
            "UAP5VEP2R": 0.2367,
            "U086M1L2F27": 0.2355,
            "U07PC9NTTNK": 0.2262,
            "U078YHXKTU7": 0.2217,
            "U4D956LSC": 0.221,
            "U086M1LK65R": 0.2145,
            "U083D8Y0YJE": 0.1953,
            "U01HB3S0UM8": 0.1905,
            "U090X2QH2QK": 0.178,
            "U05BC4D4STU": 0.177,
            "U090X2ST9NF": 0.1675,
            "U08EN6WDKCP": 0.1642,
            "U090X2M5P8B": 0.1419,
            "U3M5HJ7MX": 0.1342,
            "U090X2UUAN7": 0.132,
            "U07B3LG8M5E": 0.122,
            "U090X2ZDC91": 0.1096
        }
    },
    {
        "paper": "https://arxiv.org/abs/2507.13524",
        "summary": "Humans prefer trustworthy AI when identities are clear, but misjudge AI's prosocial actions; transparency helps humans learn and outcompete AI in forming better partnerships.",
        "matched_users": [
            "U03492H28Q3"
        ],
        "similarities": {
            "U03492H28Q3": 0.472,
            "UAP5VEP2R": 0.4551,
            "U083D8Y0YJE": 0.455,
            "U1LB1DXJS": 0.4405,
            "UUQ287SEQ": 0.4332,
            "U08DG6LRQ3V": 0.4231,
            "U079D5P6P3M": 0.4061,
            "U03KJ9NJ1FU": 0.3849,
            "U06FXPDH4TF": 0.384,
            "U025KUM8NSY": 0.3708,
            "U086M1L2F27": 0.3115,
            "U0332SAEU6P": 0.3109,
            "U090X2QH2QK": 0.3093,
            "U07PC9NTTNK": 0.284,
            "U07B3LG8M5E": 0.2799,
            "U05BC4D4STU": 0.2786,
            "U086M1LK65R": 0.2706,
            "U078YHXKTU7": 0.2697,
            "U07ABUCJWDT": 0.2694,
            "U8JLRRXPB": 0.2634,
            "U01HB3S0UM8": 0.2526,
            "U06AJGGHZ5L": 0.2458,
            "U4D956LSC": 0.234,
            "U090X2M5P8B": 0.2192,
            "U08EN6WDKCP": 0.2156,
            "U3M5HJ7MX": 0.1931,
            "U090X2ST9NF": 0.1913,
            "U090X2ZDC91": 0.1656,
            "U090X2UUAN7": 0.1652
        }
    },
    {
        "paper": "https://arxiv.org/abs/2507.07935",
        "summary": "The paper analyzes 200k real user-AI conversations to measure AI's impact on work activities, finding strong relevance for knowledge, communication, and service occupations, mainly aiding information gathering and writing tasks.",
        "matched_users": [
            "U083D8Y0YJE",
            "U1LB1DXJS"
        ],
        "similarities": {
            "U083D8Y0YJE": 0.5193,
            "U1LB1DXJS": 0.5145,
            "U03492H28Q3": 0.4806,
            "UAP5VEP2R": 0.4488,
            "U079D5P6P3M": 0.4412,
            "UUQ287SEQ": 0.4287,
            "U06FXPDH4TF": 0.4135,
            "U025KUM8NSY": 0.3999,
            "U06AJGGHZ5L": 0.3876,
            "U08DG6LRQ3V": 0.3636,
            "U0332SAEU6P": 0.3595,
            "U07ABUCJWDT": 0.349,
            "U086M1LK65R": 0.3377,
            "U086M1L2F27": 0.3352,
            "U8JLRRXPB": 0.3244,
            "U03KJ9NJ1FU": 0.317,
            "U090X2ST9NF": 0.2891,
            "U078YHXKTU7": 0.2887,
            "U05BC4D4STU": 0.2809,
            "U090X2QH2QK": 0.2726,
            "U08EN6WDKCP": 0.2621,
            "U07B3LG8M5E": 0.253,
            "U4D956LSC": 0.2503,
            "U07PC9NTTNK": 0.2487,
            "U01HB3S0UM8": 0.2309,
            "U3M5HJ7MX": 0.2138,
            "U090X2ZDC91": 0.2075,
            "U090X2M5P8B": 0.2016,
            "U090X2UUAN7": 0.1526
        }
    },
    {
        "paper": "https://arxiv.org/abs/2507.22358",
        "summary": "Magentic-UI is an open-source, human-in-the-loop AI system that combines user oversight with AI to safely and effectively perform complex tasks like web browsing, coding, and data management.",
        "matched_users": [
            "U03492H28Q3"
        ],
        "similarities": {
            "U03492H28Q3": 0.4384,
            "UAP5VEP2R": 0.4351,
            "U1LB1DXJS": 0.4174,
            "U086M1L2F27": 0.387,
            "U079D5P6P3M": 0.3824,
            "UUQ287SEQ": 0.3815,
            "U025KUM8NSY": 0.3632,
            "U083D8Y0YJE": 0.3558,
            "U06FXPDH4TF": 0.3551,
            "U078YHXKTU7": 0.3471,
            "U090X2ZDC91": 0.3256,
            "U06AJGGHZ5L": 0.3211,
            "U08DG6LRQ3V": 0.318,
            "U07B3LG8M5E": 0.2995,
            "U086M1LK65R": 0.2994,
            "U05BC4D4STU": 0.2965,
            "U090X2QH2QK": 0.294,
            "U0332SAEU6P": 0.2871,
            "U03KJ9NJ1FU": 0.2859,
            "U08EN6WDKCP": 0.2684,
            "U07ABUCJWDT": 0.2674,
            "U8JLRRXPB": 0.2476,
            "U07PC9NTTNK": 0.2262,
            "U4D956LSC": 0.2136,
            "U090X2M5P8B": 0.2006,
            "U01HB3S0UM8": 0.1989,
            "U090X2UUAN7": 0.1968,
            "U3M5HJ7MX": 0.1787,
            "U090X2ST9NF": 0.1641
        }
    },
    {
        "paper": "https://arxiv.org/abs/2508.00723",
        "summary": "The paper explores why decision-makers across domains do or don’t adopt AI, highlighting factors like background, perceptions, consequences, and stakeholder impact, offering a practical framework for responsible AI deployment.",
        "matched_users": [
            "UAP5VEP2R"
        ],
        "similarities": {
            "UAP5VEP2R": 0.4699,
            "U083D8Y0YJE": 0.4213,
            "U079D5P6P3M": 0.3891,
            "U1LB1DXJS": 0.38,
            "U03492H28Q3": 0.3725,
            "U025KUM8NSY": 0.359,
            "UUQ287SEQ": 0.3577,
            "U06FXPDH4TF": 0.3467,
            "U08DG6LRQ3V": 0.3444,
            "U078YHXKTU7": 0.3423,
            "U03KJ9NJ1FU": 0.3219,
            "U0332SAEU6P": 0.2963,
            "U8JLRRXPB": 0.283,
            "U086M1L2F27": 0.2739,
            "U06AJGGHZ5L": 0.2608,
            "U07B3LG8M5E": 0.2581,
            "U086M1LK65R": 0.2575,
            "U07PC9NTTNK": 0.2563,
            "U4D956LSC": 0.2533,
            "U05BC4D4STU": 0.2509,
            "U07ABUCJWDT": 0.2264,
            "U01HB3S0UM8": 0.2216,
            "U08EN6WDKCP": 0.2191,
            "U090X2QH2QK": 0.2095,
            "U090X2ST9NF": 0.203,
            "U3M5HJ7MX": 0.1946,
            "U090X2ZDC91": 0.1906,
            "U090X2M5P8B": 0.1781,
            "U090X2UUAN7": 0.162
        }
    },
    {
        "paper": "https://arxiv.org/abs/2406.12465",
        "summary": "The paper introduces RIGL, a fun, unified model that tracks how students learn alone and in groups, revealing their dynamic knowledge progress and relationships over time for smarter education insights.",
        "matched_users": [
            "U07ABUCJWDT"
        ],
        "similarities": {
            "U07ABUCJWDT": 0.4213,
            "U03492H28Q3": 0.3708,
            "U07PC9NTTNK": 0.3523,
            "U079D5P6P3M": 0.3452,
            "U1LB1DXJS": 0.333,
            "U06FXPDH4TF": 0.3232,
            "U090X2M5P8B": 0.3214,
            "U08DG6LRQ3V": 0.3108,
            "U090X2UUAN7": 0.3084,
            "U0332SAEU6P": 0.3063,
            "U06AJGGHZ5L": 0.3012,
            "U025KUM8NSY": 0.2996,
            "U090X2QH2QK": 0.2983,
            "U090X2ST9NF": 0.2896,
            "U8JLRRXPB": 0.28,
            "UUQ287SEQ": 0.2765,
            "U3M5HJ7MX": 0.2737,
            "U01HB3S0UM8": 0.2707,
            "U03KJ9NJ1FU": 0.2693,
            "U086M1LK65R": 0.2684,
            "UAP5VEP2R": 0.2639,
            "U083D8Y0YJE": 0.2603,
            "U090X2ZDC91": 0.2576,
            "U086M1L2F27": 0.2573,
            "U4D956LSC": 0.2496,
            "U078YHXKTU7": 0.2427,
            "U05BC4D4STU": 0.2193,
            "U08EN6WDKCP": 0.2025,
            "U07B3LG8M5E": 0.176
        }
    },
    {
        "paper": "https://arxiv.org/abs/2507.21071",
        "summary": "The paper introduces FingerTip 20K, a fun benchmark to create smarter mobile agents that proactively predict user needs and personalize app interactions, making phone use easier and more intuitive.",
        "matched_users": [],
        "similarities": {
            "UUQ287SEQ": 0.343,
            "UAP5VEP2R": 0.339,
            "U03492H28Q3": 0.3387,
            "U1LB1DXJS": 0.3187,
            "U025KUM8NSY": 0.3164,
            "U083D8Y0YJE": 0.3125,
            "U079D5P6P3M": 0.3068,
            "U0332SAEU6P": 0.3059,
            "U086M1L2F27": 0.299,
            "U05BC4D4STU": 0.2914,
            "U07B3LG8M5E": 0.2866,
            "U086M1LK65R": 0.2811,
            "U090X2QH2QK": 0.2791,
            "U06AJGGHZ5L": 0.2776,
            "U08DG6LRQ3V": 0.2736,
            "U078YHXKTU7": 0.2693,
            "U06FXPDH4TF": 0.2678,
            "U08EN6WDKCP": 0.2515,
            "U03KJ9NJ1FU": 0.2505,
            "U090X2ZDC91": 0.2335,
            "U07ABUCJWDT": 0.2327,
            "U8JLRRXPB": 0.2293,
            "U01HB3S0UM8": 0.2164,
            "U090X2ST9NF": 0.1888,
            "U07PC9NTTNK": 0.1807,
            "U090X2M5P8B": 0.1559,
            "U090X2UUAN7": 0.1395,
            "U4D956LSC": 0.1349,
            "U3M5HJ7MX": 0.1211
        }
    },
    {
        "paper": "https://arxiv.org/abs/2508.13141",
        "summary": "The paper introduces OptimalThinkingBench, a unified benchmark evaluating large language models on overthinking and underthinking, revealing current models struggle to balance accuracy and efficiency across diverse tasks.",
        "matched_users": [
            "U025KUM8NSY"
        ],
        "similarities": {
            "U025KUM8NSY": 0.3728,
            "U8JLRRXPB": 0.3618,
            "U06FXPDH4TF": 0.3572,
            "U079D5P6P3M": 0.3347,
            "U08DG6LRQ3V": 0.3131,
            "U06AJGGHZ5L": 0.2869,
            "UUQ287SEQ": 0.281,
            "U03KJ9NJ1FU": 0.2777,
            "U086M1L2F27": 0.2661,
            "U086M1LK65R": 0.2472,
            "U07ABUCJWDT": 0.2458,
            "U03492H28Q3": 0.2412,
            "U078YHXKTU7": 0.2407,
            "U07PC9NTTNK": 0.2379,
            "U1LB1DXJS": 0.2362,
            "U083D8Y0YJE": 0.2246,
            "U090X2ST9NF": 0.2196,
            "U4D956LSC": 0.2155,
            "UAP5VEP2R": 0.2076,
            "U0332SAEU6P": 0.2071,
            "U01HB3S0UM8": 0.2042,
            "U090X2QH2QK": 0.2003,
            "U05BC4D4STU": 0.1655,
            "U08EN6WDKCP": 0.1619,
            "U090X2M5P8B": 0.1403,
            "U090X2UUAN7": 0.1341,
            "U3M5HJ7MX": 0.1221,
            "U07B3LG8M5E": 0.1125,
            "U090X2ZDC91": 0.0955
        }
    },
    {
        "paper": "https://arxiv.org/abs/2508.14395",
        "summary": "NoteIt automatically turns instructional videos into interactive, structured, multimodal notes, capturing hierarchical content, key visuals, and verbal info, customizable for diverse user needs and video types.",
        "matched_users": [
            "U090X2UUAN7"
        ],
        "similarities": {
            "U090X2UUAN7": 0.3565,
            "U090X2QH2QK": 0.2964,
            "U07ABUCJWDT": 0.2944,
            "U01HB3S0UM8": 0.2895,
            "U06AJGGHZ5L": 0.27,
            "U06FXPDH4TF": 0.2606,
            "U03492H28Q3": 0.2603,
            "U1LB1DXJS": 0.2552,
            "U079D5P6P3M": 0.2527,
            "U086M1L2F27": 0.2478,
            "U086M1LK65R": 0.2478,
            "U090X2ZDC91": 0.2443,
            "U0332SAEU6P": 0.2404,
            "U08EN6WDKCP": 0.231,
            "U07PC9NTTNK": 0.2291,
            "U4D956LSC": 0.2259,
            "U090X2M5P8B": 0.221,
            "UAP5VEP2R": 0.2095,
            "U8JLRRXPB": 0.2093,
            "U025KUM8NSY": 0.205,
            "U078YHXKTU7": 0.1973,
            "U08DG6LRQ3V": 0.1844,
            "U3M5HJ7MX": 0.1768,
            "U07B3LG8M5E": 0.1754,
            "U05BC4D4STU": 0.1722,
            "UUQ287SEQ": 0.1699,
            "U090X2ST9NF": 0.1534,
            "U03KJ9NJ1FU": 0.1342,
            "U083D8Y0YJE": 0.1256
        }
    },
    {
        "paper": "https://arxiv.org/abs/2508.14160",
        "summary": "RynnEC is a compact video multimodal language model that understands objects and space, helping robots perceive and interact with the physical world more precisely and flexibly during complex tasks.",
        "matched_users": [
            "U086M1L2F27"
        ],
        "similarities": {
            "U086M1L2F27": 0.4239,
            "U06FXPDH4TF": 0.3961,
            "U079D5P6P3M": 0.3478,
            "U08DG6LRQ3V": 0.335,
            "U8JLRRXPB": 0.3343,
            "U06AJGGHZ5L": 0.3193,
            "U03492H28Q3": 0.3154,
            "U025KUM8NSY": 0.3116,
            "UUQ287SEQ": 0.2842,
            "U090X2QH2QK": 0.2786,
            "U01HB3S0UM8": 0.2692,
            "U03KJ9NJ1FU": 0.2682,
            "U1LB1DXJS": 0.2647,
            "U078YHXKTU7": 0.2594,
            "U07ABUCJWDT": 0.2537,
            "UAP5VEP2R": 0.2478,
            "U090X2UUAN7": 0.2407,
            "U086M1LK65R": 0.2401,
            "U0332SAEU6P": 0.2386,
            "U07PC9NTTNK": 0.2157,
            "U090X2M5P8B": 0.2093,
            "U05BC4D4STU": 0.1984,
            "U07B3LG8M5E": 0.1966,
            "U08EN6WDKCP": 0.19,
            "U083D8Y0YJE": 0.1841,
            "U090X2ST9NF": 0.1835,
            "U090X2ZDC91": 0.181,
            "U3M5HJ7MX": 0.181,
            "U4D956LSC": 0.1622
        }
    },
    {
        "paper": "https://arxiv.org/pdf/2509.08010",
        "summary": "This paper highlights the importance of measuring and reducing overreliance on large language models to prevent mistakes, dependence, and societal risks, ensuring AI boosts human skills and safety.",
        "matched_users": [
            "U025KUM8NSY"
        ],
        "similarities": {
            "U025KUM8NSY": 0.4701,
            "U079D5P6P3M": 0.4136,
            "U06FXPDH4TF": 0.3979,
            "U03492H28Q3": 0.3917,
            "U1LB1DXJS": 0.3798,
            "UUQ287SEQ": 0.3658,
            "U03KJ9NJ1FU": 0.3591,
            "U08DG6LRQ3V": 0.3495,
            "UAP5VEP2R": 0.3447,
            "U083D8Y0YJE": 0.3224,
            "U8JLRRXPB": 0.318,
            "U07PC9NTTNK": 0.3177,
            "U06AJGGHZ5L": 0.3068,
            "U086M1L2F27": 0.2971,
            "U086M1LK65R": 0.2719,
            "U07ABUCJWDT": 0.2386,
            "U078YHXKTU7": 0.2336,
            "U07B3LG8M5E": 0.2293,
            "U0332SAEU6P": 0.2227,
            "U090X2QH2QK": 0.2226,
            "U4D956LSC": 0.2114,
            "U090X2ST9NF": 0.1966,
            "U01HB3S0UM8": 0.1961,
            "U3M5HJ7MX": 0.1861,
            "U08EN6WDKCP": 0.1687,
            "U05BC4D4STU": 0.1677,
            "U090X2ZDC91": 0.15,
            "U090X2M5P8B": 0.1491,
            "U090X2UUAN7": 0.1381
        }
    },
    {
        "paper": "https://arxiv.org/abs/2504.10445",
        "summary": "The paper introduces RealWebAssist, a new benchmark testing AI's ability to follow complex, real-world long-term web instructions, highlighting current models' limitations and the need for smarter, reasoning-capable agents.",
        "matched_users": [
            "U06FXPDH4TF"
        ],
        "similarities": {
            "U06FXPDH4TF": 0.434,
            "UUQ287SEQ": 0.4218,
            "U079D5P6P3M": 0.4102,
            "U03492H28Q3": 0.3843,
            "U08DG6LRQ3V": 0.3759,
            "UAP5VEP2R": 0.375,
            "U083D8Y0YJE": 0.3692,
            "U025KUM8NSY": 0.3562,
            "U090X2QH2QK": 0.3504,
            "U8JLRRXPB": 0.3502,
            "U1LB1DXJS": 0.3447,
            "U03KJ9NJ1FU": 0.3365,
            "U078YHXKTU7": 0.336,
            "U086M1LK65R": 0.3344,
            "U0332SAEU6P": 0.3335,
            "U086M1L2F27": 0.3225,
            "U07B3LG8M5E": 0.2903,
            "U07ABUCJWDT": 0.2843,
            "U01HB3S0UM8": 0.2808,
            "U05BC4D4STU": 0.2706,
            "U06AJGGHZ5L": 0.2684,
            "U07PC9NTTNK": 0.2371,
            "U090X2ST9NF": 0.2361,
            "U4D956LSC": 0.214,
            "U090X2ZDC91": 0.2094,
            "U090X2UUAN7": 0.2014,
            "U08EN6WDKCP": 0.1973,
            "U090X2M5P8B": 0.1821,
            "U3M5HJ7MX": 0.151
        }
    },
    {
        "paper": "https://arxiv.org/abs/2509.13348",
        "summary": "The paper introduces \"Learn Your Way,\" a Google AI system that personalizes and enriches textbooks with multiple modes, assessments, and content transformations, boosting learning effectiveness through AI-driven adaptation.",
        "matched_users": [
            "U03492H28Q3"
        ],
        "similarities": {
            "U03492H28Q3": 0.4524,
            "U1LB1DXJS": 0.4342,
            "U06FXPDH4TF": 0.3988,
            "U07ABUCJWDT": 0.3922,
            "U079D5P6P3M": 0.3832,
            "U025KUM8NSY": 0.3725,
            "U07PC9NTTNK": 0.3635,
            "U090X2QH2QK": 0.3594,
            "UUQ287SEQ": 0.3576,
            "U078YHXKTU7": 0.3428,
            "U090X2UUAN7": 0.3392,
            "UAP5VEP2R": 0.3384,
            "U086M1L2F27": 0.3278,
            "U083D8Y0YJE": 0.3252,
            "U06AJGGHZ5L": 0.3248,
            "U090X2ZDC91": 0.3223,
            "U08DG6LRQ3V": 0.3196,
            "U086M1LK65R": 0.3108,
            "U01HB3S0UM8": 0.3041,
            "U0332SAEU6P": 0.2938,
            "U8JLRRXPB": 0.2892,
            "U05BC4D4STU": 0.26,
            "U090X2ST9NF": 0.2564,
            "U08EN6WDKCP": 0.2496,
            "U07B3LG8M5E": 0.2432,
            "U090X2M5P8B": 0.2426,
            "U3M5HJ7MX": 0.2416,
            "U03KJ9NJ1FU": 0.2357,
            "U4D956LSC": 0.226
        }
    }
]